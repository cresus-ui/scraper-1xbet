# 1xBet Scraper - Apify Actor

ğŸ† **Scraper professionnel pour 1xbet.com** - Extraction complÃ¨te de donnÃ©es sportives prÃ©-match et post-match avec monitoring avancÃ©.

## ğŸ“‹ Description

Cet Actor Apify permet d'extraire des donnÃ©es sportives complÃ¨tes depuis 1xbet.com, incluant :

### ğŸ¯ DonnÃ©es PrÃ©-Match
- **Matchs Ã  venir** avec Ã©quipes, cotes et horaires
- **Cotes dÃ©taillÃ©es** (1X2, Over/Under, Handicap, etc.)
- **Compositions d'Ã©quipes** et joueurs
- **Conditions mÃ©tÃ©orologiques** pour les matchs en extÃ©rieur
- **Statistiques des Ã©quipes** et historique

### ğŸ“Š DonnÃ©es Post-Match
- **RÃ©sultats finaux** et scores dÃ©taillÃ©s
- **Ã‰vÃ©nements de match** (buts, cartons, remplacements)
- **Statistiques complÃ¨tes** (possession, tirs, passes, etc.)
- **Performances individuelles** des joueurs
- **RÃ©sumÃ©s de match** et analyses

### ğŸ”§ FonctionnalitÃ©s AvancÃ©es
- **Monitoring en temps rÃ©el** avec alertes
- **Limitation de taux intelligente** pour Ã©viter les blocages
- **Gestion d'erreurs robuste** avec retry automatique
- **Validation des donnÃ©es** avec Pydantic
- **Support multi-sports** (Football, Basketball, Tennis, etc.)
- **Extraction parallÃ¨le** pour optimiser les performances

## ğŸš€ Installation et Configuration

### PrÃ©requis
- Python 3.8+
- Compte Apify (pour dÃ©ploiement)
- Docker (optionnel, pour dÃ©veloppement local)

### Installation Locale

```bash
# Cloner le repository
git clone https://github.com/cresus-ui/scraper-1xbet.git
cd scraper-1xbet

# Installer les dÃ©pendances
pip install -r requirements.txt

# Installer Playwright (pour le rendu JavaScript)
playwright install chromium
```

### Configuration

CrÃ©ez un fichier `.env` (optionnel) :

```env
# Configuration optionnelle
APIFY_TOKEN=your_apify_token
LOG_LEVEL=INFO
MAX_RETRIES=3
REQUEST_DELAY=2
```

## ğŸ“– Utilisation

### ğŸ® Via Apify Console

1. **AccÃ©dez Ã  l'Actor** sur [Apify Console](https://console.apify.com)
2. **Configurez les paramÃ¨tres** d'entrÃ©e
3. **Lancez l'extraction** et surveillez les rÃ©sultats
4. **TÃ©lÃ©chargez les donnÃ©es** au format JSON/CSV/Excel

### ğŸ’» DÃ©veloppement Local

```bash
# ExÃ©cution directe
python -m src.main

# Avec configuration personnalisÃ©e
python -m src.main --config config.json

# Mode debug
python -m src.main --debug
```

### ğŸ³ Avec Docker

```bash
# Build de l'image
docker build -t 1xbet-scraper .

# ExÃ©cution
docker run -v $(pwd)/data:/app/data 1xbet-scraper
```

## âš™ï¸ Configuration d'EntrÃ©e

### ParamÃ¨tres Principaux

```json
{
  "sports": ["football", "basketball", "tennis"],
  "extraction_type": "both",
  "max_matches_per_sport": 50,
  "include_odds": true,
  "include_statistics": true,
  "include_lineups": true,
  "date_range": {
    "start_date": "2024-01-01",
    "end_date": "2024-01-31"
  },
  "output_format": "json",
  "monitoring": {
    "enable_alerts": true,
    "health_check_interval": 300,
    "max_error_rate": 0.1
  }
}
```

### Options AvancÃ©es

| ParamÃ¨tre | Type | Description | DÃ©faut |
|-----------|------|-------------|--------|
| `sports` | Array | Sports Ã  extraire | `["football"]` |
| `extraction_type` | String | `"prematch"`, `"postmatch"`, `"both"` | `"both"` |
| `max_matches_per_sport` | Number | Limite par sport | `100` |
| `include_odds` | Boolean | Inclure les cotes | `true` |
| `include_statistics` | Boolean | Inclure les statistiques | `true` |
| `include_lineups` | Boolean | Inclure les compositions | `false` |
| `parallel_requests` | Number | RequÃªtes parallÃ¨les | `3` |
| `request_delay` | Number | DÃ©lai entre requÃªtes (sec) | `2` |
| `max_retries` | Number | Tentatives max | `3` |

## ğŸ“Š Format de Sortie

### Structure des DonnÃ©es

```json
{
  "matches": [
    {
      "match_id": "12345",
      "sport": "football",
      "competition": "Premier League",
      "teams": {
        "home": {
          "name": "Manchester United",
          "logo": "https://...",
          "odds": 2.1
        },
        "away": {
          "name": "Liverpool",
          "logo": "https://...",
          "odds": 3.2
        }
      },
      "match_time": "2024-01-15T15:00:00Z",
      "status": "upcoming",
      "odds": {
        "1x2": {"1": 2.1, "x": 3.4, "2": 3.2},
        "over_under": {"over_2_5": 1.8, "under_2_5": 2.0}
      },
      "statistics": {
        "possession": {"home": 55, "away": 45},
        "shots": {"home": 12, "away": 8}
      },
      "events": [
        {
          "minute": "23",
          "type": "goal",
          "player": "Marcus Rashford",
          "team": "home"
        }
      ]
    }
  ],
  "metadata": {
    "extracted_at": "2024-01-15T10:30:00Z",
    "total_matches": 150,
    "sports_covered": ["football", "basketball"],
    "extraction_duration": "00:05:23"
  }
}
```

## ğŸ” Monitoring et MÃ©triques

### Tableau de Bord

L'Actor fournit des mÃ©triques dÃ©taillÃ©es :

- **Taux de succÃ¨s** par sport et type d'extraction
- **Temps de rÃ©ponse** moyen des requÃªtes
- **Erreurs dÃ©tectÃ©es** et actions correctives
- **Utilisation des ressources** (CPU, mÃ©moire)
- **Progression en temps rÃ©el** de l'extraction

### Alertes Automatiques

- **Taux d'erreur Ã©levÃ©** (>10%)
- **Temps de rÃ©ponse lent** (>30s)
- **Blocage dÃ©tectÃ©** par le site
- **DonnÃ©es manquantes** ou incohÃ©rentes

## ğŸ› ï¸ Architecture Technique

### Modules Principaux

```
src/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e principal
â”œâ”€â”€ config.py              # Configuration et validation
â”œâ”€â”€ session_manager.py     # Gestion des sessions Playwright
â”œâ”€â”€ data_processor.py      # Traitement et validation des donnÃ©es
â”œâ”€â”€ monitoring.py          # SystÃ¨me de monitoring
â””â”€â”€ extractors/
    â”œâ”€â”€ prematch_extractor.py   # Extraction prÃ©-match
    â””â”€â”€ postmatch_extractor.py  # Extraction post-match
```

### Technologies UtilisÃ©es

- **[Playwright](https://playwright.dev/)** - Automatisation navigateur
- **[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)** - Parsing HTML
- **[Pydantic](https://pydantic-docs.helpmanual.io/)** - Validation des donnÃ©es
- **[Asyncio](https://docs.python.org/3/library/asyncio.html)** - Programmation asynchrone
- **[Apify SDK](https://docs.apify.com/sdk/python/)** - IntÃ©gration plateforme

## ğŸš¨ Gestion d'Erreurs

### StratÃ©gies de RÃ©cupÃ©ration

1. **Retry automatique** avec backoff exponentiel
2. **Rotation des User-Agents** pour Ã©viter la dÃ©tection
3. **Gestion des timeouts** avec dÃ©lais adaptatifs
4. **Validation des donnÃ©es** avant stockage
5. **Alertes en temps rÃ©el** pour intervention manuelle

### Codes d'Erreur

| Code | Description | Action |
|------|-------------|--------|
| `E001` | Site inaccessible | Retry avec dÃ©lai |
| `E002` | Captcha dÃ©tectÃ© | Pause et retry |
| `E003` | DonnÃ©es manquantes | Log et continue |
| `E004` | Rate limit atteint | Attente et retry |
| `E005` | Erreur de parsing | Validation et skip |

## ğŸ“ˆ Performance

### Optimisations

- **Extraction parallÃ¨le** jusqu'Ã  5 threads
- **Cache intelligent** pour Ã©viter les requÃªtes dupliquÃ©es
- **Compression des donnÃ©es** pour rÃ©duire l'usage mÃ©moire
- **Pagination optimisÃ©e** pour les grandes listes
- **SÃ©lecteurs CSS optimisÃ©s** pour un parsing rapide

### Benchmarks

- **~200 matchs/minute** en mode standard
- **~500 matchs/minute** en mode rapide (sans statistiques dÃ©taillÃ©es)
- **Utilisation mÃ©moire** : ~100MB pour 1000 matchs
- **Taux de succÃ¨s** : >95% en conditions normales

## ğŸ¤ Contribution

### DÃ©veloppement

```bash
# Fork et clone
git clone https://github.com/votre-username/scraper-1xbet.git

# CrÃ©er une branche
git checkout -b feature/nouvelle-fonctionnalite

# Installer en mode dÃ©veloppement
pip install -e .

# Lancer les tests
pytest tests/

# VÃ©rifier le code
flake8 src/
black src/
```

### Guidelines

1. **Tests unitaires** obligatoires pour nouvelles fonctionnalitÃ©s
2. **Documentation** mise Ã  jour
3. **Code style** : Black + Flake8
4. **Commits** : Convention Conventional Commits
5. **Pull Request** avec description dÃ©taillÃ©e

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

### Ressources

- **[Documentation Apify](https://docs.apify.com/)**
- **[Issues GitHub](https://github.com/cresus-ui/scraper-1xbet/issues)**
- **[Discord Apify](https://discord.com/invite/jyEM2PRvMU)**

### Contact

Pour toute question ou support :

- ğŸ“§ **Email** : support@cresus-ui.com
- ğŸ’¬ **Discord** : Rejoignez notre serveur
- ğŸ› **Bugs** : CrÃ©ez une issue GitHub

---

**â­ Si ce projet vous aide, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**

*DÃ©veloppÃ© avec â¤ï¸ par l'Ã©quipe Cresus UI*
